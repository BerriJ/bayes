\documentclass[12pt,a4paper]{article}
\usepackage{lmodern}

\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[lmargin = 5cm,rmargin = 2.5cm,tmargin = 2.5cm,bmargin = 2.5cm]{geometry}

% Figure Placement:
\usepackage{float}
\let\origfigure\figure
\let\endorigfigure\endfigure
\renewenvironment{figure}[1][2] {
    \expandafter\origfigure\expandafter[H]
} {
    \endorigfigure
}

%%%% Jens %%%%
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{numprint}
\npthousandsep{\,}

%% citation setup
\usepackage{csquotes}

\usepackage[backend=biber, maxbibnames = 99, style = apa]{biblatex}
\setlength\bibitemsep{1.5\itemsep}
\addbibresource{R_packages.bib}
\bibliography{references.bib}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true, linktocpage = TRUE]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={Jens Klenke},
            pdftitle={Bayes Seminar},
            colorlinks=true,
            citecolor=black,
            urlcolor=black,
            linkcolor=black,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{5}

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Bayes Seminar}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
\subtitle{Advanced R for Econometricians}
  \author{Jens Klenke}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{today}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

%% linespread settings

\usepackage{setspace}

\onehalfspacing

% Language Setup

\usepackage{ifthen}
\usepackage{iflang}
\usepackage[super]{nth}
\usepackage[ngerman, english]{babel}

%Acronyms
\usepackage[printonlyused, withpage, nohyperlinks]{acronym}
\usepackage{changepage}

% Multicols for the Title page
\usepackage{multicol}

\begin{document}

\selectlanguage{english}

%%%%%%%%%%%%%% Jens %%%%%
\numberwithin{equation}{section}


%\maketitle

\begin{titlepage}
  \noindent\begin{minipage}{0.6\textwidth}
	  \IfLanguageName{english}{University of Duisburg-Essen}{Universität Duisburg-Essen}\\
	  \IfLanguageName{english}{Faculty of Business Administration and Economics}{Fakultät für Wirtschaftswissensschaften}\\
	  \IfLanguageName{english}{Chair of Econometrics}{Lehrstuhl für Ökonometrie}\\
  \end{minipage}
	\begin{minipage}{0.4\textwidth}
	  \begin{flushright}
  	  \vspace{-0.5cm}
      \IfLanguageName{english}{\includegraphics*[width=5cm]{Includes/duelogo_en.png}}{\includegraphics*[width=5cm]{Includes/duelogo_de.png}}
	  \end{flushright}
	\end{minipage}
  \\
  \vspace{1.5cm}
  \begin{center}
  \huge{Bayes Seminar}\\
  \vspace{.25cm}
  \Large{Advanced R for Econometricians}\\
  \vspace{0.5cm}
  \large{Seminar Paper}\\
  \vspace{1cm}
  \large{  \IfLanguageName{english}{Submitted to the Faculty of \\ Ökonometrie  \\at the \\University of Duisburg-Essen}{Vorgelegt der \\Fakultät für Wirtschaftswissenschaften der \\ Universität Duisburg-Essen}\\}
  \vspace{0.75cm}
  \large{\IfLanguageName{english}{from:}{von:}}\\
  \vspace{0.5cm}
  Jens Klenke\\
  \end{center}
  %\vspace{2cm}
  \vfill
  \hrulefill

  \noindent\begin{minipage}[t]{0.3\textwidth}
  \IfLanguageName{english}{Reviewer:}{Erstgutachter:}
  \end{minipage}
  \begin{minipage}[t]{0.7\textwidth}
  \hspace{1cm}Christoph Hanck
  \end{minipage}

  \noindent\begin{minipage}[t]{0.3\textwidth}
  \IfLanguageName{english}{Deadline:}{Abgabefrist:}
  \end{minipage}
  \begin{minipage}[t]{0.7\textwidth}
  \hspace{1cm}Jan.~17th 2020
  \end{minipage}

  \hrulefill

  \begin{multicols}{2}

  Name:

  Matriculation Number:

  E-Mail:

  Study Path:

  Semester:

  Graduation (est.):
 
  \columnbreak

  Jens Klenke

  3071594
  
  jens.klenke@stud.uni-due.de

  M.Sc. Economics

  \nth{5}

  Winter Term 2020

	\end{multicols}

\end{titlepage}

\newgeometry{top=2cm, left = 5cm, right = 2.5cm, bottom = 2.5cm}


\pagenumbering{Roman}
{
\hypersetup{linkcolor=black}

\setcounter{tocdepth}{3}
\tableofcontents
}

\newpage
\listoffigures
\addcontentsline{toc}{section}{List of Figures}

%\newpage
\listoftables
\addcontentsline{toc}{section}{List of Tables}

\section*{List of Abbreviations}
\addcontentsline{toc}{section}{List of Abbreviations}

\begin{adjustwidth}{1.5em}{0pt}

\begin{acronym}[dummyyyy]
 \acro{bagging}{Bootstrap Aggregation}
 \acro{LASSO}{Least Absolute Shrinkage and Selection Operator}
 \acro{pcr}{Principal Components Regression}
 \acro{pls}{Partial Least Squares}
 \acro{RMSE}{Root Mean Squared Error}
 \acro{MCMC}{Markov chain Monte Carlo} 
 \acro{i.i.d.}{independent and identically distributed}
 \acroplural{LRG}[LRG]{längefristige Refinanzierungsgeschäfte}

%Falls eine Abkürzung in der Mehrzahl nicht einfach auf "s" endet muss das speziell eingestellt werden.
% \acro{slmtA}{super lange mega tolle Abkürzung} %Einzahl
 %\acroplural{slmtA}[slmtAs]{super lange mega tolle Abkürzungen} %Mehrzahl
 \acro{dummyyyy}{dummyyy}
\end{acronym}

\end{adjustwidth}

\restoregeometry

\newpage
\pagenumbering{arabic}
\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In recent years, the \ac{LASSO} method of
\textcite{tibshirani_regression_1996} has emerged as an alternative to
ordinary least squares estimation. The success of the method is mainly
due to its ability to perform both variable selection and estimation. As
already Tibshirani pointed out in his original paper the standard
\ac{LASSO} model can be interpreted as a linear regression with a
Laplace prior. PARK and CASELLA where the first to implement the
Bayesian l\ac{LASSO} \textgreater\textgreater using a conditional
Laplace prior specification\textless\textless.

Our goal is to compare the result of the Bayesian \ac{LASSO} with normal
\ac{LASSO} method and an ordinary least square estimation. The focus is
particularly on the number of non-significant parameters in the linear
model or, in case of the \acp{LASSO} the parameters equal to zero.

\newpage

\hypertarget{theory-of-bayesian-inference}{%
\section{Theory of Bayesian
inference}\label{theory-of-bayesian-inference}}

The Bayesian (inference) statistics based on the Bayes' theorem for
events.

\begin{align}
\label{eq:bayes_theorem}
  P(A | B) = \dfrac{P (B | A) P(A)}{P(B)}
\end{align}

For Bayesian statistics the event theorem gets \eqref{eq:bayes_theorem}
rewritten to apply it to densities. Where \(\pi (\theta)\) is the prior
distribution - which could be gained from prior research or knowledge,
\(f(y | \theta )\) is the likelihood function, and \(\pi (\theta| y)\)
is the posterior distribution, we then get the following.

\begin{align}
\label{eq:bayes_dens}
  \pi (\theta | y) = \dfrac{f(y | \theta) \pi(\theta)}{f(y)}
\end{align}

From \eqref{eq:bayes_dens} the advantages and disadvantages of Bayesian
statistics compared to frequentist statistics can directly be retrieved.
One major adavantage is that the Bayesian approach can account for prior
knowledge and points out a philosophical difference to the frequentist
approach - that the obtained data stands not alone. Another, key
difference and advantage is that in the Bayesian world the computation
are made with distributions and this leads to a better information level
than just the computation of the first and second moment. The
computation of distributions are also the greatest disadvantages or more
neutral the biggest problem of the Bayesian approach because in high
dimensional problems the computation takes a lot of times or is
sometimes even not possible. A solution to that is that with newer and
better computers it is possible to simulate the integrals with a
\ac{MCMC} method. \autocite[p.~100]{ghosh_introduction_2006} PAGE
NUMBER!! \newpage

\hypertarget{data-description}{%
\section{Data description}\label{data-description}}

We collected the data from the online database platform \emph{kaggel.}
The dataset included 6 years of data for all players which were included
in the soccer simulation game \emph{FIFA} from \emph{EA Sports}. We
decided to just keep the data for 2019 and 2020. The Data for 2019
contains 17538 datapoints will be used for the estimation of the
different models whereas the 2020 data with 18028 will be used to
compare the quality of the models with an out of sample \ac{RMSE}. Both
datasets consist of 104 variables which will not all be included in the
estimations. Some Variables are just an ID or different length of names
and URLs. \autocite{leone_fifa_2020}

A fundamental problem of the dataset was that goalkeepers are
systematically rated differently than field players. Therefore, in the
subcategories of \emph{overall} all field player categories were
assigned NAs for goalkeepers. Conversely, all field players have NAs in
all goalkeeper categories. Because the algorithm of \ac{LASSO} in R
cannot handle NAs, they are set to zero for all models.

It is not very realistic that a fielder has no values in the goalkeeper
categories and vice versa. However, it can be argued, at least for
outfield players, that goalkeeper attributes play no role in determining
market values. This argumentation does not seem to hold for goalkeepers,
at least passing can be assumed to be an influential variable for the
market value, because is an essential asset for the passing game if the
ball is in the goalkeeper's hands. Nevertheless, due to the lack of
alternatives, all NAs have been replaced by zero.

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-3}\label{tab:sum} Summary of some important variables for the 2019 FIFA edition}
\centering
\begin{tabular}[t]{lllrlrr}
\toprule
 & year &  & N &   & mean & sd\\
\midrule
\rowcolor{gray!6}  value\_eur & 2019 &  & 17 538 &  & 2 473 043.68 & 5 674 963.22\\
 & 2020 &  & 18 028 &  & 2 518 484.58 & 5 616 359.21\\
\rowcolor{gray!6}  wage\_eur & 2019 &  & 17 538 &  & 10 085.87 & 22 448.70\\
 & 2020 &  & 18 028 &  & 9 584.81 & 21 470.29\\
\rowcolor{gray!6}  overall & 2019 &  & 17 538 &  & 66.23 & 7.01\\
 & 2020 &  & 18 028 &  & 66.21 & 6.95\\
\rowcolor{gray!6}  age & 2019 &  & 17 538 &  & 25.17 & 4.64\\
 & 2020 &  & 18 028 &  & 25.23 & 4.63\\
\rowcolor{gray!6}  potential & 2019 &  & 17 538 &  & 71.40 & 6.15\\
 & 2020 &  & 18 028 &  & 71.56 & 6.14\\
\bottomrule
\end{tabular}
\end{table}

As one can see in Table \ref{tab:sum} the differences between the
editions for the most important variables are considerable small. For
example, from 2019 to 2020 the mean player \emph{value} (response
variable) increased by 4.54e+04 which is about 1.8 per cent or 0.01
standard deviations. Similar results are observable for the probably
most important righthand variables \emph{wage} and \emph{overall} with a
difference in the means of -0.02 and -0.003 standard deviations between
2019 and 2020.

\begin{figure}
\centering
\includegraphics{term_paper_bayes_files/figure-latex/fig1-1.pdf}
\caption{\label{fig:hist_1} Histograms of player values and log player
values}
\end{figure}

As can be seen for the variable value in Figure \ref{fig:hist_1}, this
relatively strong right-skew is distributed, a similar pattern can be
observed for the variable wage. Since we also estimate a linear model,
and this often leads to non-normally distributed residuals, these were
logarithmized.

\newpage

\hypertarget{used-models}{%
\section{Used Models}\label{used-models}}

To compare the Bayesian \ac{LASSO} we will analyse the data also with a
linear multivariate model, and the frequentist \ac{LASSO}. We wil start
with the linear model and will modifie the model equations step by step
forwards the bayesian version.

\hypertarget{linear-model}{%
\subsection{Linear Model}\label{linear-model}}

The frequentist multivariate regression model has the follwing model
equation.

\begin{align}
\label{eq:lm}
\pmb{Y = \beta_0 + X \beta} + \pmb{\epsilon}
\end{align}

Where \(\pmb{y}\) is the \(n \times 1\) response vector, \(\pmb{X}\) is
the \(n \times p\) matrix of regressors and, \(\pmb{\epsilon}\) is the
\(n \times 1\) vecotr of \ac{i.i.d.} errors with mean 0 and unknown
variance \(\sigma^2\). The coefficient will be estimated by the ordinary
least square method, which means that \(\pmb{\beta}\) should be chosen
so that the \emph{Euclidean norm}
\(\left( || \mathbf{y - X\beta} ||_2 \right)\) is minimal. This yields
in the conditon for the estimation of coefficients:

\begin{align}
\label{eq:lm_con}
 \hat{\pmb{\beta}} = \argmin_{ \pmb{\beta}} (\pmb{y - \beta_0 - X  \beta})^T (\pmb{y - \beta_0 - X  \beta})
\end{align}

\hypertarget{section}{%
\subsection{\texorpdfstring{\acf{LASSO}}{}}\label{section}}

In the \ac{LASSO} method the model equation is the same as the equation
for the multivariate but the condition for the optimization of the
estimators in equation \eqref{eq:lm_con} has an additional punishment
term. Which leads to the optimazation of:

\begin{align}
\label{eq:la_con}
\hat{\pmb{\beta}} = \argmin_{\pmb{\beta}}  \left( \pmb{y - X \beta} \right)^T \left( \pmb{y - X \beta} \right) + \lambda \sum_{i = 1}^{p} |\beta_j|
\end{align}

for some \(\lambda \geq 0\). This method is also often referred to as
\(L_1\) -penalized least squares estimation.

Already in his original paper \textcite{tibshirani_regression_1996} has
pointed out the possibility that his methods can also be interpreted
Bayesian. The LASSO estimates can be considered as posterior mode
estimates with a double-exponential Laplace prior.

\hypertarget{bayesian-lasso}{%
\subsection{Bayesian Lasso}\label{bayesian-lasso}}

\textcite{park_bayesian_2008} considered a fully Bayesian approach using
a conditional Laplace prior of the form

\begin{align} 
\label{eq:la_bay_prior}
 \pi \left( \pmb{\beta} | \sigma^2 \right)   = \prod_{j = 1}^{p} \dfrac{\lambda}{2 \sqrt{\sigma^e}} e^{\dfrac{- \lambda |\beta_j |}{\sqrt{\sigma^2}}} 
\end{align}

\autocite{park_bayesian_2008}

\hypertarget{gibbs-sampler-and-the-full-model-specification}{%
\subsubsection{Gibbs Sampler and the full Model
specification}\label{gibbs-sampler-and-the-full-model-specification}}

The Gibbs Sampler is a special case of an \ac{MCMC} algorithm, which is
useful to approximate the combianed distribution of two or more
regressors in a multidemsinoal problem.

The algortithm tries to find the approximate joint distribution and
therefore the algortihm runs through the subvectors \(\beta\) and draws
ach subset conditional on all other values.
\autocite{gelman_bayesian_2004}

Bayesian \ac{LASSO} the Gibbs sampler in the \textbf{monomvn} package in
\textbf{R} {[}gramacy\_monomvn\_2019{]} samples from the following
representation of the Laplace distribution

\begin{align} 
\label{eq:gibbs}
  \dfrac{a}{2}e^{-a |z|} = \int_{0}^{\infty} \dfrac{1}{2 \sqrt{\sigma^2}} e^{ -z^2 / (2s)} \; \dfrac{a^2}{2} e^{ -a^2 s /2} ds, \qquad a > 0 
\end{align}

\textcite{andrews_scale_1974}

The full model has the following hierarchical representation

\begin{align} 
\label{eq:hier}
  \pmb{y|\mu}, \pmb{X}, \pmb{\beta}, \sigma^2 & \sim N_n (\mu \pmb{1}_n + \pmb{X \beta}, \sigma^2  \pmb{I}_n)   \nonumber\\
  \pmb{\beta} | \sigma^2, \tau^2_1 , \ldots , \tau^2_p & \sim N_p (\pmb{0}_p , \sigma^2 \pmb{D}_{\tau}) \nonumber \\
  \pmb{D}_{\tau} & = diag(\tau^2_1 , \ldots , \tau^2_p)\\
  \sigma^2, \tau^2_1 , \ldots , \tau^2_p & \sim \pi \left( \sigma^2 \right) d \sigma^2 \prod_{j = 1}^{p} \dfrac{\lambda^2}{2}e^{- \lambda^2 \tau^2_j /2} d \tau^2_j \nonumber \\
  \sigma^2, \tau^2_1 , \ldots , \tau^2_p & > 0 \nonumber \\
\end{align}

If \(\tau^2_1 , \ldots , \tau^2_p\) gets integreted out of the
conditional prior on \(\pmb{\beta}\) , we get the form of
\eqref{eq:la_bay_prior}. For \(\sigma^2\) the inverse-gamma function of
the form \(\pi \left( \sigma^2 \right) = \dfrac{1}{\sigma^2}\) was
implemented in the \textbf{monomvn} package.

\hypertarget{estimation-of-the-models}{%
\section{Estimation of the Models}\label{estimation-of-the-models}}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-4}\label{tab:sum_lm} Summary of the linear model}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
  & Estimate & Std. Error & t value & Pr(>|t|)\\
\midrule
\rowcolor{gray!6}  (Intercept) & -8.5970 & 2.9222 & -2.9420 & 0.0033\\
log\_wage & 0.0679 & 0.0025 & 26.8466 & 0.0000\\
\rowcolor{gray!6}  age & -0.1004 & 0.0008 & -119.6665 & 0.0000\\
height\_cm & 0.0012 & 0.0004 & 2.7140 & 0.0067\\
\rowcolor{gray!6}  weight\_kg & 0.0001 & 0.0004 & 0.3175 & 0.7508\\
overall & 0.2098 & 0.0008 & 266.5231 & 0.0000\\
\rowcolor{gray!6}  potential & -0.0059 & 0.0007 & -8.1962 & 0.0000\\
shooting & 0.0049 & 0.0003 & 17.7691 & 0.0000\\
\rowcolor{gray!6}  contract\_valid\_until & 0.0051 & 0.0014 & 3.5164 & 0.0004\\
pace & 0.0008 & 0.0002 & 3.6118 & 0.0003\\
\rowcolor{gray!6}  passing & 0.0019 & 0.0004 & 4.5131 & 0.0000\\
dribbling & -0.0016 & 0.0005 & -3.4678 & 0.0005\\
\rowcolor{gray!6}  defending & -0.0017 & 0.0002 & -10.6851 & 0.0000\\
\bottomrule
\end{tabular}
\end{table}

\begin{table}

\caption{\label{tab:unnamed-chunk-5}\label{tab:sum_lasso} Summary of the LASSO }
\centering
\begin{tabular}[t]{ll}
\toprule
  & Estimate\\
\midrule
\rowcolor{gray!6}  (Intercept) & 1.72337\\
log\_wage & 0.066023\\
\rowcolor{gray!6}  age & -0.089616\\
height\_cm & -\\
\rowcolor{gray!6}  weight\_kg & -\\
overall & 0.200689\\
\rowcolor{gray!6}  potential & 0.001541\\
shooting & 0.004659\\
\rowcolor{gray!6}  contract\_valid\_until & -\\
pace & -\\
\rowcolor{gray!6}  passing & -\\
dribbling & -\\
\rowcolor{gray!6}  defending & -0.000213\\
\bottomrule
\end{tabular}
\end{table}

\begin{table}

\caption{\label{tab:unnamed-chunk-6}\label{tab:sum_bay} Summary of the Bayesian LASSO }
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & median & 2.5\% & 97.5\%\\
\midrule
\rowcolor{gray!6}  log\_wage & 0.067554 & 0.063834 & 0.071904\\
age & -0.100611 & -0.102215 & -0.098671\\
\rowcolor{gray!6}  height\_cm & 0.001264 & 0.000000 & 0.002029\\
weight\_kg & 0.000000 & 0.000000 & 0.000000\\
\rowcolor{gray!6}  overall & 0.209992 & 0.208272 & 0.211500\\
potential & -0.006020 & -0.007445 & -0.004492\\
\rowcolor{gray!6}  shooting & 0.004856 & 0.004186 & 0.005391\\
contract\_valid\_until & 0.004777 & 0.000000 & 0.008346\\
\rowcolor{gray!6}  pace & 0.000714 & 0.000000 & 0.001135\\
passing & 0.001771 & 0.000000 & 0.002559\\
\rowcolor{gray!6}  dribbling & -0.001549 & -0.002438 & 0.000000\\
defending & -0.001596 & -0.001960 & -0.001072\\
\rowcolor{gray!6}  variance & 0.057742 & 0.056657 & 0.058963\\
lambda.square & 0.000124 & 0.000037 & 0.000356\\
\bottomrule
\end{tabular}
\end{table}

\begin{table}

\caption{\label{tab:unnamed-chunk-7}\label{tab:sum_bay_hy} Summary of the  Bayessian LASSO with hyperpriors}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & median & 2.5\% & 97.5\%\\
\midrule
\rowcolor{gray!6}  beta1 & 0.067405 & 0.061796 & 0.072935\\
beta2 & -0.100695 & -0.102174 & -0.099112\\
\rowcolor{gray!6}  beta3 & 0.001274 & 0.000000 & 0.002045\\
beta4 & 0.000000 & 0.000000 & 0.000446\\
\rowcolor{gray!6}  beta5 & 0.209832 & 0.208392 & 0.211174\\
beta6 & -0.005893 & -0.007389 & -0.004306\\
\rowcolor{gray!6}  beta7 & 0.004792 & 0.004169 & 0.005301\\
beta8 & 0.004703 & 0.000000 & 0.007556\\
\rowcolor{gray!6}  beta9 & 0.000497 & 0.000000 & 0.001049\\
beta10 & 0.001454 & 0.000000 & 0.002508\\
\rowcolor{gray!6}  beta11 & -0.000977 & -0.002296 & 0.000000\\
beta12 & -0.001553 & -0.001958 & -0.001094\\
\rowcolor{gray!6}  variance & 0.057671 & 0.056589 & 0.058846\\
lambda.square & 0.000087 & 0.000028 & 0.000340\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{parameter-results-and-posteriod-based-prediction}{%
\section{Parameter Results and (Posteriod-based)
prediction}\label{parameter-results-and-posteriod-based-prediction}}

\hypertarget{residuals-and-sensitive-analysis}{%
\section{Residuals and Sensitive
Analysis}\label{residuals-and-sensitive-analysis}}

\hypertarget{discussion-and-further-research}{%
\section{Discussion and further
research}\label{discussion-and-further-research}}

\newpage

\renewcommand*{\mkbibnamefamily}[1]{\textbf{#1}}
\renewcommand*{\mkbibnamegiven}[1]{\textbf{#1}}
\renewcommand*{\mkbibnameprefix}[1]{\textbf{#1}}
\renewcommand*{\mkbibnamesuffix}[1]{\textbf{#1}}
\printbibliography[title=References]



\newpage
\textbf{Eidesstattliche Versicherung}

\bigskip

Ich versichere an Eides statt durch meine Unterschrift, dass ich die vorstehende Arbeit selbständig und ohne fremde Hilfe angefertigt und alle Stellen, die ich wörtlich oder annähernd wörtlich aus Veröffentlichungen entnommen habe, als solche kenntlich gemacht habe, mich auch keiner anderen als der angegebenen Literatur oder sonstiger Hilfsmittel bedient habe. Die Arbeit hat in dieser oder ähnlicher Form noch keiner anderen Prüfungsbehörde vorgelegen.

\vspace{1cm}
\rule{0pt}{2\baselineskip} %
\par\noindent\makebox[2.25in]{\indent Essen, den \hrulefill} \hfill\makebox[2.25in]{\hrulefill}%
\par\noindent\makebox[2.25in][l]{} \hfill\makebox[2.25in][c]{Jens Klenke}%


\end{document}
